from transformers import (
    AutoModelForSequenceClassification,
    AutoTokenizer,
    Trainer,
    TrainingArguments,
)
from data_prep import load_and_tokenize

# âœ… STEP 1: Load tokenized dataset
print("ğŸ›  Loading and tokenizing dataset...")
dataset = load_and_tokenize()
print("âœ… Dataset loaded.")

# âœ… STEP 2: Load model and tokenizer
print("ğŸ›  Loading BERT model and tokenizer...")
model = AutoModelForSequenceClassification.from_pretrained(
    "bert-base-uncased", num_labels=2
)
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
print("âœ… Model and tokenizer ready.")

# âœ… STEP 3: Define training arguments
print("ğŸ›  Setting up training arguments...")
training_args = TrainingArguments(
    output_dir="./results",                  # Where to save the model
    num_train_epochs=3,                      # Number of epochs
    per_device_train_batch_size=8,           # Training batch size
    per_device_eval_batch_size=8,            # Evaluation batch size
    evaluation_strategy="epoch",             # Run eval each epoch
    save_strategy="epoch",                   # Save checkpoint after each epoch
    logging_dir="./logs",                    # Where to log
    load_best_model_at_end=True,             # Restore best model after training
    logging_steps=50,                        # Log every 50 steps
    # Uncomment next line to debug faster:
    max_steps=10,                          # â›”ï¸ Only 10 steps for testing â€” REMOVE in final version!
)
print("âœ… Training arguments set.")

# âœ… STEP 4: Initialize the Trainer
print("ğŸ›  Initializing Trainer...")
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset["train"],
    eval_dataset=dataset["validation"],
    tokenizer=tokenizer,  # Important: this must be the actual tokenizer object
)
print("âœ… Trainer ready.")

# âœ… STEP 5: Start training
print("ğŸš€ Starting training...")
trainer.train()
print("âœ… Training complete!")

# âœ… Done!
print("ğŸ“¦ Model saved at: ./results")
